{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1878949",
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests.compat import urlparse, urljoin\n",
    "from requests.exceptions import HTTPError\n",
    "import time\n",
    "import sqlite3\n",
    "from requests import Session\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "def download(url, params={}, headers={}, method='GET', limit=3):\n",
    "    try:\n",
    "        session = Session()\n",
    "        resp = session.request(method, url,\n",
    "                               params=params if method.upper() == 'GET' else '',\n",
    "                               data=params if method.upper() == 'POST' else '',\n",
    "                               headers=headers)\n",
    "        resp.raise_for_status()\n",
    "    except HTTPError as e:\n",
    "        if limit > 0 and e.response.status_code >= 500:\n",
    "            print(limit)\n",
    "            time.sleep(60)  # Server Error이기 때문에 delay를 두고 실행하기 위해서 사용한다.\n",
    "            # 보통은 5분에 한 번꼴로 random하게 되도록 설정한다.\n",
    "            download(url, params, headers, method, limit - 1)\n",
    "        else:\n",
    "            print('[{}] '.format(e.response.status_code) + url)\n",
    "            print(e.response.reason)\n",
    "            print(e.response.headers)\n",
    "\n",
    "    return resp\n",
    "\n",
    "def crawl(code, time):\n",
    "    headers = {\"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.131 Safari/537.36\"}\n",
    "\n",
    "    date = time[:8]\n",
    "    \n",
    "    result = list()\n",
    "    pages = range(1, 41)\n",
    "    for page in pages:\n",
    "        url = 'https://finance.naver.com/item/sise_time.nhn?code={}&thistime={}&page={}'.format(code, time, page)\n",
    "        resp = download(url, headers = headers)\n",
    "        dom = BeautifulSoup(resp.content, 'lxml')\n",
    "        \n",
    "        result.extend([(date, t, p) for t, p in zip([i.text for i in dom.select('tr> td:nth-child(1) > span')], [i.text for i in dom.select('tr> td:nth-child(2) > span')])])\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a2a385e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|███████████████████████████████████████████████████████▋                         | 11/16 [20:07<09:09, 109.81s/it]\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect('Stock.db')\n",
    "cur = conn.cursor()\n",
    "\n",
    "# cur.executescript('''\n",
    "#             DROP TABLE IF EXISTS stock;\n",
    "#             CREATE TABLE stock(\n",
    "#                 pk INTEGER PRIMARY KEY AUTOINCREMENT NOT NULL,\n",
    "#                 code TEXT NOT NULL,\n",
    "#                 date TEXT NOT NULL,\n",
    "#                 time TEXT NOT NULL,\n",
    "#                 price TEXT NOT NULL\n",
    "#             );\n",
    "#         ''')\n",
    "\n",
    "codes = {'336260', '009830', '086520', '011930', '018000', '035720', '035420', '036570', '041140', '018260', '005930', '000660', '011790', '014680', '000990', '023530', '004170', '008770', '028260', '026960', '105560', '071050', '055550', '316140', '086790', '047080', '089890', '030350', '230980', '069410'}\n",
    "\n",
    "data = {i:[] for i in codes}\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "year = now.year\n",
    "month = now.month\n",
    "day = now.day\n",
    "\n",
    "if cur.execute('SELECT date FROM stock ORDER BY date DESC').fetchone():\n",
    "    seen_date = cur.execute('SELECT date FROM stock ORDER BY date DESC').fetchone()[0]\n",
    "else:\n",
    "    seen_date = None\n",
    "\n",
    "\n",
    "for i in tqdm(range(16)):\n",
    "    now = datetime.datetime(year, month, day)\n",
    "    if now.weekday() == 5 or now.weekday() == 6:\n",
    "        pass\n",
    "    else:\n",
    "        if month < 10:\n",
    "            if day < 10:\n",
    "                time = str(year) + '0' + str(month) + '0' + str(day) + '161122'\n",
    "            else:\n",
    "                time = str(year) + '0' + str(month) + str(day) + '161122'\n",
    "        else:\n",
    "            if day < 10:\n",
    "                time = str(year) + str(month) + '0' + str(day) + '161122'\n",
    "            else:\n",
    "                time = str(year) + str(month) + str(day) + '161122'\n",
    "        \n",
    "        # 만약 해당 날짜가 DB에 있으면, 그 이전 날짜의 데이터도 모두 있는 것이므로 break\n",
    "        if int(time[:8]) <= int(seen_date):\n",
    "            break\n",
    "        else:\n",
    "            for code in codes:\n",
    "                result = crawl(code, time)\n",
    "                for date, t, price in result:\n",
    "                    cur.execute('INSERT INTO stock(code, date, time, price) VALUES(?,?,?,?)',\n",
    "                                                         [code, date, t, price])\n",
    "                    conn.commit()\n",
    "#         for code in codes:\n",
    "#             data[code].extend(crawl(code, time))\n",
    "        \n",
    "    day -= 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
